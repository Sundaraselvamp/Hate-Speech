{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06603ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\GUVI\\Hate Speech\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input,Dense, GlobalMaxPooling1D\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9273952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_folder=\"data\\Text file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dfe3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96049307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom spaCy tokenizer\n",
    "def spacy_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af57add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read text from files based on file_id\n",
    "def read_text_from_file(file_id):\n",
    "    file_path=os.path.join(text_folder,f'{file_id}.txt')\n",
    "    try:\n",
    "        with open(file_path,'r',encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d3eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data\\Annotations_Metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc51016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['actual_text']=data['file_id'].apply(lambda file_id: read_text_from_file(file_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and tokenize the text\n",
    "data['preprocessed_text']=data['actual_text'].apply(lambda text:' '.join(spacy_tokenizer(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ae504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels using LabelEncoder for multi-class classification\n",
    "label_encoder = LabelEncoder()\n",
    "data['label_encoded'] = label_encoder.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacae7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize and pad the sequences\n",
    "sequences = data['preprocessed_text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=100, truncation=True))\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, data['label_encoded'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using DistilBERT with functional API\n",
    "input_layer = Input(shape=(100,), dtype='int32')\n",
    "distilbert_layer = TFDistilBertModel.from_pretrained('distilbert-base-uncased', trainable=False)(input_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(distilbert_layer.last_hidden_state)\n",
    "output_layer = Dense(len(label_encoder.classes_), activation='softmax')(pooling_layer)\n",
    "\n",
    "model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02952213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on the test set\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = y_pred_probs.argmax(axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c1bf95",
   "metadata": {},
   "source": [
    "False Positive/Negative Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positive/Negative Analysis\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices of false positives and false negatives\n",
    "false_positive_indices = [i for i in range(len(y_test)) if y_test_labels[i] == 'noHate' and y_pred_labels[i] == 'hate']\n",
    "false_negative_indices = [i for i in range(len(y_test)) if y_test_labels[i] == 'hate' and y_pred_labels[i] == 'noHate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display false positives\n",
    "print(\"\\nFalse Positives:\")\n",
    "for idx in false_positive_indices:\n",
    "    print(f\"Actual: {y_test_labels[idx]}, Predicted: {y_pred_labels[idx]}, Text: {data['preprocessed_text'][idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display false negatives\n",
    "print(\"\\nFalse Negatives:\")\n",
    "for idx in false_negative_indices:\n",
    "    print(f\"Actual: {y_test_labels[idx]}, Predicted: {y_pred_labels[idx]}, Text: {data['preprocessed_text'][idx]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
